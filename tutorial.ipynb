{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Alrao (All learning rates at once) : a tutorial\n",
    "\n",
    "We show in this notebook how to use Alrao in practice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import argparse\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "\n",
    "from alrao import AlraoModel\n",
    "from alrao import SGDAlrao, AdamAlrao\n",
    "from alrao import lr_sampler_generic, generator_randomlr_neurons, generator_randomlr_weights\n",
    "\n",
    "# CUDA\n",
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading\n",
    "We use the CIFAR10 dataset. We also use some data augmentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./datasets', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./datasets', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining the preclassifier model\n",
    "We define a pre-classifier model. This model can be defined exactly as any usual model. Only two things are specific with alrao : \n",
    "* First, there is no classifier. The classifier layer will be added later\n",
    "* The model needs the have a `linearinputdim` attribute , which is the output's dimension of the pre-classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VGG(nn.Module): # identical to models.VGG\n",
    "    def __init__(self, cfg):\n",
    "        super(VGG, self).__init__()\n",
    "        self.features = self._make_layers(cfg)\n",
    "        # The dimension of the preclassier's output need to be specified.\n",
    "        self.linearinputdim = 512\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        # The model do not contain a classifier layer.\n",
    "        return out\n",
    "\n",
    "    def _make_layers(self, cfg):\n",
    "        layers = []\n",
    "        in_channels = 3\n",
    "        for x in cfg:\n",
    "            if x == 'M':\n",
    "                layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
    "            else:\n",
    "                layers += [nn.Conv2d(in_channels, x, kernel_size=3, padding=1),\n",
    "                           nn.BatchNorm2d(x),\n",
    "                           nn.ReLU(inplace=True)]\n",
    "                in_channels = x\n",
    "        layers += [nn.AvgPool2d(kernel_size=1, stride=1)]\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "preclassifier = VGG([64, 64, 'M', 128, 128, 'M', 256, 256, 256, 256, 'M',\n",
    "                     512, 512, 512, 512, 'M', 512, 512, 512, 512, 'M'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the classifier\n",
    "Here, we define our own classifier class. In practice, we do not need to redefine it, it can be found in `alrao.custom_layers.LinearClassifier`.\n",
    "We redefine it here to show how any classifier (with a log-softmax output) can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module): # identical to alrao.custom_layers.LinearClassifier\n",
    "    def __init__(self, in_features, n_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.fc = nn.Linear(in_features, n_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc(x)\n",
    "        x = nn.functional.log_softmax(x, dim=1)\n",
    "        return x\n",
    "    \n",
    "criterion = nn.NLLLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the modified architecture for Alrao\n",
    "We define the new architecture, with the parallel classifiers.\n",
    "</img><img src=\"img/newalrao.png\" width=\"400\"></img>\n",
    "\n",
    "Here there are 10 categories, and we decide to use 10 classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb_classifiers is the number of classifiers averaged by Alrao.\n",
    "nb_classifiers = 10\n",
    "nb_categories = 10\n",
    "net = AlraoModel(preclassifier, nb_classifiers, Classifier, preclassifier.linearinputdim, nb_categories)\n",
    "if use_cuda: net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sampling the learning rates\n",
    "We choose an interval (`minLR`, `maxLR`) in which the learning rates are chosen.\n",
    "For the pre-classifier, the learning rates are sampled from the log-uniform distribution $\\log-U(\\cdot ; \\eta_{\\min}, \\eta_{\\max})$ :\n",
    "namely, if $\\eta \\sim \\log-U(\\cdot ; \\eta_{\\min},\n",
    "\\eta_{\\max})$, then $\\log \\eta$ is uniformly distributed between $\\log\n",
    "\\eta_{\\min}$ and $\\log \\eta_{\\max}$.\n",
    "Its\n",
    "density function is\n",
    "\\begin{equation}\n",
    "  \\label{eq:logunif}\n",
    "  \\log-U(\\eta; \\eta_{\\min}, \\eta_{\\max}) = \\frac{1_{\\eta_{\\min} \\leq \\eta \\leq \\eta_{\\max}}}{\\eta_{\\max} - \\eta_{\\min}}\\times\\frac{1}{\\eta}\n",
    "\\end{equation}\n",
    "\n",
    "The learning rates of the classifier are log-uniformly spread on the interval : \n",
    "$\\log \\eta_{j} = \\log \\eta_{\\min} +\n",
    "\\frac{j-1}{N_{\\mathrm{cl}}-1}\\log(\\eta_{\\max}/ \\eta_{\\min})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the interval in which the learning rates are sampled\n",
    "minlr = 10 ** (-5)\n",
    "maxlr = 10 ** 1\n",
    "\n",
    "# We spread the classifiers learning rates log-uniformly on the interval.\n",
    "classifiers_lr = [np.exp(np.log(minlr) + \\\n",
    "    k /(nb_classifiers-1) * (np.log(maxlr) - np.log(minlr)) \\\n",
    "    ) for k in range(nb_classifiers)]\n",
    "\n",
    "# We define the sampler for the preclassifier’s features.\n",
    "lr_sampler = lr_sampler_generic(minlr, maxlr)\n",
    "lr_preclassifier = generator_randomlr_neurons(net.preclassifier, lr_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the optimizer\n",
    "We define the Alrao optimizer. This includes : \n",
    "* A single (usual) SGD optimizer for each classifier\n",
    "* A modified SGD optimizer for the pre-classifier, allowing to use one learning rate per neuron.\n",
    "* The switch model averaging method, with its own update procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = SGDAlrao(net.parameters_preclassifier(),\n",
    "                     lr_preclassifier,\n",
    "                     net.classifiers_parameters_list(),\n",
    "                     classifiers_lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training procedure\n",
    "We define the train procedure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    pbar = tqdm(total=len(trainloader.dataset),bar_format='{l_bar}{bar}| {n_fmt}/{total_fmt} {postfix}')\n",
    "    pbar.set_description(\"Epoch %d\" % epoch)\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        net.train()\n",
    "        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        # We update the model averaging weights in the optimizer\n",
    "        optimizer.update_posterior(net.posterior())\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass of the Alrao model\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # We compute the gradient of all the model’s weights\n",
    "        loss.backward()\n",
    "\n",
    "        # We reset all the classifiers gradients, and re-compute them with\n",
    "        # as if their were the only output of the network.\n",
    "        optimizer.classifiers_zero_grad()\n",
    "        newx = net.last_x.detach()\n",
    "        for classifier in net.classifiers():\n",
    "            loss_classifier = criterion(classifier(newx), targets)\n",
    "            loss_classifier.backward()\n",
    "\n",
    "        # Then, we can run an update step of the gradient descent.\n",
    "        optimizer.step()\n",
    "\n",
    "        # Finally, we update the model averaging weights\n",
    "        net.update_switch(targets, catch_up=False)\n",
    "\n",
    "        # Update loss\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "        # Update progression bar\n",
    "        pbar.update(batch_size)\n",
    "        postfix = OrderedDict([(\"LossTrain\",\"{:.4f}\".format(train_loss/(batch_idx+1))),\n",
    "                               (\"AccTrain\", \"{:.3f}\".format(100.*correct/total))])\n",
    "        postfix[\"PostSw\"] = net.repr_posterior()\n",
    "        pbar.set_postfix(postfix)\n",
    "    pbar.close()\n",
    "\n",
    "    # Print performance of the classifiers\n",
    "    cl_perf = net.switch.get_cl_perf()\n",
    "    for k in range(len(cl_perf)):\n",
    "        print(\"Classifier {}\\t LossTrain:{:.6f}\\tAccTrain:{:.4f}\".format(\n",
    "            k, cl_perf[k][0], cl_perf[k][1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(epoch):\n",
    "    net.eval()\n",
    "    net.switch.reset_cl_perf()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "        net.eval()\n",
    "        if use_cuda: inputs, targets = inputs.cuda(), targets.cuda()\n",
    "\n",
    "        # Forward pass of the Alrao model\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Update loss\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets).sum().item()\n",
    "\n",
    "    print('\\tLossTest: %.4f\\tAccTest: %.3f' % (test_loss/(batch_idx+1), 100.*correct/total))\n",
    "    print((\"Posterior : \"+\"{:.1e}, \" * nb_classifiers).format(*net.posterior()))\n",
    "\n",
    "    return test_loss / (batch_idx + 1), correct / total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0:   0%|          | 0/50000 /usr/local/lib/python3.5/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='elementwise_mean' instead.\n",
      "  warnings.warn(warning.format(ret))\n",
      "Epoch 0: : 50016it [01:08, 734.15it/s, LossTrain=1.4912, AccTrain=44.960, PostSw=|  █       |]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0\t LossTrain:2.337866\tAccTrain:0.1637\n",
      "Classifier 1\t LossTrain:2.177651\tAccTrain:0.2126\n",
      "Classifier 2\t LossTrain:1.491529\tAccTrain:0.4495\n",
      "Classifier 3\t LossTrain:1.593359\tAccTrain:0.4239\n",
      "Classifier 4\t LossTrain:1.511902\tAccTrain:0.4416\n",
      "Classifier 5\t LossTrain:1.584111\tAccTrain:0.4145\n",
      "Classifier 6\t LossTrain:3.459628\tAccTrain:0.3357\n",
      "Classifier 7\t LossTrain:17.862085\tAccTrain:0.3163\n",
      "Classifier 8\t LossTrain:84.200117\tAccTrain:0.3188\n",
      "Classifier 9\t LossTrain:385.173223\tAccTrain:0.3209\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1:   0%|          | 0/50000 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLossTest: 1.6407\tAccTest: 48.350\n",
      "Posterior : 1.0e-04, 1.2e-04, 9.9e-01, 1.3e-03, 2.8e-03, 6.4e-04, 7.5e-05, 6.2e-05, 6.2e-05, 6.2e-05, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1: : 50016it [01:08, 677.93it/s, LossTrain=1.0398, AccTrain=63.140, PostSw=|  █       |]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0\t LossTrain:2.190358\tAccTrain:0.2145\n",
      "Classifier 1\t LossTrain:1.724247\tAccTrain:0.4703\n",
      "Classifier 2\t LossTrain:1.039695\tAccTrain:0.6314\n",
      "Classifier 3\t LossTrain:1.073514\tAccTrain:0.6238\n",
      "Classifier 4\t LossTrain:1.061550\tAccTrain:0.6235\n",
      "Classifier 5\t LossTrain:1.136726\tAccTrain:0.6007\n",
      "Classifier 6\t LossTrain:2.577442\tAccTrain:0.5183\n",
      "Classifier 7\t LossTrain:12.325342\tAccTrain:0.5012\n",
      "Classifier 8\t LossTrain:57.199303\tAccTrain:0.4994\n",
      "Classifier 9\t LossTrain:265.525891\tAccTrain:0.5019\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 2:   0%|          | 0/50000 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLossTest: 0.9826\tAccTest: 65.570\n",
      "Posterior : 4.3e-05, 6.4e-05, 1.0e+00, 1.4e-03, 1.5e-03, 3.1e-04, 5.2e-05, 3.1e-05, 3.0e-05, 3.0e-05, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2: : 50016it [01:07, 738.08it/s, LossTrain=0.8426, AccTrain=70.528, PostSw=|  █       |]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classifier 0\t LossTrain:1.990107\tAccTrain:0.2853\n",
      "Classifier 1\t LossTrain:1.378167\tAccTrain:0.6083\n",
      "Classifier 2\t LossTrain:0.842532\tAccTrain:0.7054\n",
      "Classifier 3\t LossTrain:0.864112\tAccTrain:0.6977\n",
      "Classifier 4\t LossTrain:0.862863\tAccTrain:0.6969\n",
      "Classifier 5\t LossTrain:0.940143\tAccTrain:0.6752\n",
      "Classifier 6\t LossTrain:2.238621\tAccTrain:0.6050\n",
      "Classifier 7\t LossTrain:10.572438\tAccTrain:0.5899\n",
      "Classifier 8\t LossTrain:48.966449\tAccTrain:0.5907\n",
      "Classifier 9\t LossTrain:230.978295\tAccTrain:0.5883\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 3:   0%|          | 0/50000 "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tLossTest: 0.8048\tAccTest: 71.720\n",
      "Posterior : 3.6e-05, 6.6e-05, 1.0e+00, 1.3e-03, 9.3e-04, 1.6e-04, 2.1e-05, 2.0e-05, 2.0e-05, 2.0e-05, \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3:   3%|▎         | 1408/50000 , LossTrain=0.7753, AccTrain=73.366, PostSw=|  █       |Process Process-13:\n",
      "Process Process-14:\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/process.py\", line 252, in _bootstrap\n",
      "    self.run()\n",
      "Traceback (most recent call last):\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/process.py\", line 93, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/torch/utils/data/dataloader.py\", line 96, in _worker_loop\n",
      "    r = index_queue.get(timeout=MANAGER_STATUS_CHECK_INTERVAL)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/queues.py\", line 104, in get\n",
      "    if timeout < 0 or not self._poll(timeout):\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/connection.py\", line 257, in poll\n",
      "    return self._poll(timeout)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/connection.py\", line 414, in _poll\n",
      "    r = wait([self], timeout)\n",
      "KeyboardInterrupt\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/multiprocessing/connection.py\", line 911, in wait\n",
      "    ready = selector.select(timeout)\n",
      "  File \"/home/parietal/lblier/miniconda3/envs/test/lib/python3.5/selectors.py\", line 376, in select\n",
      "    fd_event_list = self._poll.poll(timeout)\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-83e4bf63836a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-8-9a7148ed2baf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m     25\u001b[0m         \u001b[0mnewx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_x\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifiers\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mloss_classifier\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnewx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mloss_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-4-3dffe58d157d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctional\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 477\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    478\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    479\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbias\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1023\u001b[0m         \u001b[0;31m# fused op is marginally faster\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1024\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0maddmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "Epoch 3:   3%|▎         | 1408/50000 , LossTrain=0.7753, AccTrain=73.366, PostSw=|  █       |"
     ]
    }
   ],
   "source": [
    "for epoch in range(50):\n",
    "    train(epoch)\n",
    "    test(epoch)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
